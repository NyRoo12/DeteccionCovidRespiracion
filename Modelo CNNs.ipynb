{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26e651f-b230-467c-83e1-86ec21f8fe49",
   "metadata": {},
   "source": [
    "# Informe del Proyecto: Clasificación de Imágenes de Espectrogramas con VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9d1c3-5d39-4752-8f00-5428acccf82c",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591e63a-f3a0-47ed-9d5d-5188f65607ea",
   "metadata": {},
   "source": [
    "El presente cuadernillo tiene como objetivo desarrollar un modelo de aprendizaje profundo para la clasificación binaria de espectrogramas, utilizando la arquitectura preentrenada VGG16. La tarea principal es identificar si una imagen pertenece a una clase específica, a partir de imágenes espectrales almacenadas en un directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff6166c-9ad7-4dc6-947d-12c3d75095c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\Vicen\\anaconda3\\envs\\tensorflow_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Module use of python38.dll conflicts with this version of Python.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Vicen\\anaconda3\\envs\\tensorflow_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:62\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Module use of python38.dll conflicts with this version of Python.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16\n",
      "File \u001b[1;32mc:\\Users\\Vicen\\anaconda3\\envs\\tensorflow_env\\Lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vicen\\anaconda3\\envs\\tensorflow_env\\Lib\\site-packages\\tensorflow\\python\\__init__.py:36\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vicen\\anaconda3\\envs\\tensorflow_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:77\u001b[0m\n\u001b[0;32m     75\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     79\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     80\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     82\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     83\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     84\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\Vicen\\anaconda3\\envs\\tensorflow_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Module use of python38.dll conflicts with this version of Python.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e1a1c-9bfa-4515-8e62-18856970386a",
   "metadata": {},
   "source": [
    "## 2.Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd031d8-a17d-42c0-bd90-9ace3e553168",
   "metadata": {},
   "source": [
    "### 2.1 Configuración de Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61885e-a9fa-4a37-8452-6a50c9fb9728",
   "metadata": {},
   "source": [
    "Se establecieron los siguientes parámetros para el preprocesamiento y la configuración del modelo:\n",
    "\n",
    "*    Altura y Ancho de Imágenes: 128x128 píxeles\n",
    "*    Tamaño de Lote (Batch Size): 32\n",
    "*    Número de Épocas: 5\n",
    "*    Directorio Base de Imágenes: Ruta específica donde se encuentran los espectrogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be424fdb-5061-49b0-91bb-b2f989e32d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters():\n",
    "    params = {\n",
    "        'img_height': 128,\n",
    "        'img_width': 128,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 5,\n",
    "        'learning_rate': 0.0001,\n",
    "        'base_dir': '/home/yvan/Escritorio/Acustic/img/Spectrograms'\n",
    "    }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b0a90-fb9c-433c-87ba-30fcb898556f",
   "metadata": {},
   "source": [
    "### 2.2 Generación de Datos de Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506679b9-1295-4333-9521-95392a6d76ce",
   "metadata": {},
   "source": [
    "Se utilizó ImageDataGenerator para realizar aumentación y normalización de imágenes. Las imágenes fueron divididas en un 80% para entrenamiento y un 20% para validación.\n",
    "\n",
    "*    Rescale: Las imágenes fueron normalizadas a un rango de 0,10,1.\n",
    "*    Aumentación: Se implementaron rotaciones, desplazamientos horizontales y verticales, y volteo horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "173f98cc-1c9b-41da-b422-29eebddadac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear generadores de datos\n",
    "def create_data_generators(base_dir, img_height, img_width, batch_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        base_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='training'\n",
    "    )\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        base_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='validation'\n",
    "    )\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c7298-7e8e-4903-9102-c59c44dd0243",
   "metadata": {},
   "source": [
    "## 3. Diseño del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c206d-b508-43ef-b6a6-88cc88edde0a",
   "metadata": {},
   "source": [
    "### 3.1 Arquitectura del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905fc1b-b59f-4803-8ee4-d4e87c598849",
   "metadata": {},
   "source": [
    "La arquitectura del modelo se basa en VGG16 preentrenado en el conjunto de datos ImageNet, con las siguientes modificaciones:\n",
    "\n",
    "*    Capas Congeladas: Todas las capas de VGG16 se congelaron para evitar la actualización de los pesos preentrenados.\n",
    "*    Capas Personalizadas: Se añadieron capas de aplanado (Flatten), densa (Dense) y de abandono (Dropout) para mejorar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6660507a-58b9-4046-b562-e1c32c7b1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear y compilar el modelo\n",
    "def create_model(img_height, img_width, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', Recall()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67664e6-9de3-4b21-a932-030a5b38f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "def train_model(model, train_generator, validation_generator, epochs):\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[reduce_lr]\n",
    "    )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8311dcaf-02c9-45e8-92c9-89824b430600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3540 images belonging to 2 classes.\n",
      "Found 884 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.8559 - loss: 0.3138 - recall_1: 0.9050 - val_accuracy: 0.8891 - val_loss: 0.2026 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0155 - recall_1: 1.0000 - val_accuracy: 0.9400 - val_loss: 0.1154 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0058 - recall_1: 1.0000 - val_accuracy: 0.9378 - val_loss: 0.1157 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0036 - recall_1: 1.0000 - val_accuracy: 0.9446 - val_loss: 0.1047 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0023 - recall_1: 1.0000 - val_accuracy: 0.9604 - val_loss: 0.0768 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "#Ejecución\n",
    "params = get_parameters()\n",
    "train_generator, validation_generator = create_data_generators(\n",
    "    params['base_dir'], params['img_height'], params['img_width'], params['batch_size']\n",
    ")\n",
    "model = create_model(params['img_height'], params['img_width'], params['learning_rate'])\n",
    "history = train_model(model, train_generator, validation_generator, params['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd00ba5-e009-43f1-9446-b1bb629c4499",
   "metadata": {},
   "source": [
    "## 4. Análisis de los Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965972d-1beb-4778-bebe-2c7ea8d6a1f5",
   "metadata": {},
   "source": [
    "El modelo fue entrenado durante 5 épocas, utilizando el generador de datos de entrenamiento y validación. Se empleó el callback ReduceLROnPlateau para reducir la tasa de aprendizaje en caso de estancamiento en la mejora de la función de pérdida.\n",
    "\n",
    "Se observa una mejora constante en la precisión del conjunto de entrenamiento con cada época, alcanzando un valor máximo del 99.08% en la última época. Sin embargo, la precisión en el conjunto de validación muestra una mejora más gradual y no alcanza valores tan altos, situándose en torno al 84%.\n",
    "\n",
    "Este comportamiento puede sugerir que el modelo podría estar empezando a sobreajustarse al conjunto de entrenamiento en épocas posteriores. Una pérdida de validación relativamente estable (disminuyendo de 0.3406 a 0.3036) indica que el modelo sigue generalizando adecuadamente, aunque puede ser beneficioso implementar regularización adicional o ajustar parámetros para mejorar la precisión de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ec3dd-c648-4f51-ae8a-2d2c03bdd027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
